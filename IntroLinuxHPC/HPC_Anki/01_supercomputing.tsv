Why should a researcher use an HPC system?	A HPC system allows a researcher access compute resources that are unavailable on a personal device. More researchers are attracted to HPC because data sets and computational complexity is increasing faster. If data sets are too large or computational complexity is too high then HPC is a good choice. It is also best if the researcher wants a managed service.
When should they seek alternatives?	If a researcher's software application requires MS-Windows, or has a very complex and specific workflow, or has a high requirement of visualisation then it is possible that alternatives will be needed (e.g., Melbourne Research Cloud). However, some parts of the problem may be suitable for HPC.
What's the difference between capacity and capability in high performance computing?	Capacity is represented by the number of cores, whereas capability is the ability to run multi-core and multi-node computational tasks. A HPC system, with capacity, could just run many single-core jobs. However, with multi-threaded applications, MPI applications, and interconnect, it can scale up to run large multi-core jobs as well.
What's special about the compute cores in high performance computing?	There is nothing special about the compute cores in HPC! They are typically commodity-standard server grade system units. However, what is different is that the system units are networked together with, with schedulers and message-passing software, can operate as a single, multi-user system.
What is a supercomputer?	A supercomputer is any single computing system that has "world's best" metrics at any point in time. In the past, supercomputers were mainframe systems. In recent decades, they are clusters ("Beowulf clusters") of commodity-grade servers. The top500.org publishes 500 public supercomputers every six months, as measure by LINPACK's calculation of floating-point operations.
What percentage of the Top 500 supercomputers use Linux as their operating system?	100% of the Top500 has been Linux since November 2017
LINPACK, used by the Top500, measures floating-point operations per second. What other metrics can be considered?	Linear equations, matrix multiplications, sustained memory bandwidth, large array transpositions, random access through table updates, fast Fourier transforms, and tests of bandwidth and latency between system nodes. Another test, the HPCG Benchmark tests against sparse matrix calculations, memory limits, and interconnect performance.
What's the difference between a supercomputer and a high performance computer?	Many definitions of "high performance computer" treat it as a synonym of "supercomputer". However, an HPC system is any computer system whose architecture allows for significantly above-average performance. It is possible (although not likely) that a computer system could be designed in a low-performance manner, but still be a "supercomputer". It is far more common that a system is high-performance, but is not really a "supercomputer"
What's the difference between a high performance computer and a cluster?	Clusters are a particular type of HPC system architecture that uses a number of standard computing units (typically rack-mounted  servers) that are connected together with some sort of (typically fast) interconnect. Message Passing software allows for the entire collection to be treated as a single computing system. Clusters make up the overwhelming majority of HPC system and all of the Top500 supercomputers.
What's the difference between high performance computing (HPC) and high throughput computing (HTC)?	Another term that is used is High Throughput Computing (HTC). This is when the system architecture is used for maximum job  completion. HTC systems are interested in how many tasks are completed, not necessarily the speed. Whilst this might sound the same (because tasks are completed in a time frame) it is really a reflection of the difference between capacity ("lots  of cores for processing") and capability ("lots of cores for complex tasks"). The latter invariably requires a high-speed  interconnect between the compute nodes and, as an opportunity cost, that means less money for processor cores.
What is "task-parallel" computation?	With task-parallel computation, there are many tasks operating independently,  in parallel, that communicate with each other. These are typically used with distributed-memory parallel applications and  across multiple nodes. The performance of such applications will depend on the amount and size of communication and the  throughput of the interconnect between compute nodes. Also, the effort to create such applications is usually higher than for shared memory systems.
What is research computing?	Reseach computing is whatever computing tools are used by researchers; note that some computer platforms are better than others for particular needs.
What makes reproducible research difficult with computing?	When software changes the results can change. A researcher must be aware of what compilers and versions, software application version, and extensions version were used. The "ten year reproducibility" challenge should be tested.
Why is it important to understand, in broad terms, the physical layout of a computing system?	Understanding the physical architecture helps diagnose errors and run jobs in a more efficient manner. It some cases it is essential to even run a job (e.g., different processor types).
Describe the architecture of a HPC cluster architecture from the node level upwards?	A cluster computer system consists of individual system units ("nodes") houses in one or more rack. The rack has a power supply to the individual compute nodes and, typically, a high-speed interconnect between the nodes.
Describe the architecture of a compute node?	The individual nodes, or system units, will contain their own memory, local disk, and sockets. The sockets will include one or more processors that have one or more cores that carry out the processing. In addition to CPUs, the system may have GPU accelerators.
What is the “management node” on an HPC cluster?	This is where the job scheduler will  determine when tasks are run, receiving information from resource daemons, running on the compute nodes, that update the  scheduler. It is also the place where system operators do a lot of their work, monitoring the system as a whole or building  software, etc.
What is the “login nodes” on an HPC cluster?	Users will access the system through one or more login nodes. It is here that they will find access to their data files, job  submission scripts, or their own programs. These will typically be accessed as mount points to other hardware. These mount  points provide a global file system that is available on all nodes of the cluster; this is especially convenient as it means  that files can be accessed directly on all nodes.
Is the login node a good place to run jobs?	Login nodes represent a bit of a bottle-neck in the architecture. Memory-intensive and multicore tasks will take resources away from everyone trying to use the system. Instead, a job submission system (e.g., Slurm) should be used instead. Don't run jobs on the login node.
Using the metaphor of a horse, cart, and a load of goods for a computing system and the task, what is the appropriate metaphor for data-parallel job processing?	Under this metaphor, a data-parallel job is one that make use of multiple horses and carts, splitting the load (the data set) across multiple horses and carts in a teamser system.
Why is driving a car a metaphor for task-parallel computation?	There are different processor tasks that operate simultaneously (hands-steering, eyes-traffic, feet-pedals) that pass messages to the brain (root process) that distributes information according to requirements. The tasks carry out different actions but depend on message-passing.
What is the difference between shared and distributed memory?	With share memory processors access a common address range and with distributed memory each processor has a private address space with data shared through message passing.
Do high performance compute clusters use shared or distributed memory?	HPC clusters use both shared and distributed memory; memory is shared within a compute node and distributed between compute nodes.
What is the data and instruction flow from with HPC job submission?	A job submission script is a text file that invokes a shell, requests resources, and is followed by shell commands. The script is typically submitted on the login node where the resource requests go to the scheduler. The scheduler tracks the resources available on the cluster compute nodes through information received by resource daemons and compares the resources and priority of the job to develop a queue of when jobs should run.
What is data parallel computation?	With data parallel computation one has a large number of datasets or independent tasks and one wishes to run the same  computational task across all of them. When there is more than one core available the datasets can be distributed among the  cores instead of running each one sequentially in a loop structure, which is a lot slower. These are typically applied in job arrays or shared  memory parallel applications on a single node.
What is task parallel computation?	With data parallel computation one has a large number of tasks that can run in parallel but need to communicate data to one another. These are usually applied with parallel programming or pre-compiled disrtibuted memory applications.
What are "embarassingly" or "pleasingly" parallel problems?	These are computational problems (data or instructions) that can be broken up into discrete and equal chunks that can be run on a single node and have minimal message passing. 
What sort of architecture did Spartan originally have?	The Spartan system was originally built on the principles of high throughput computing (HTC). It had a small traditional HPC partition and a larger partition consisting of VMs from the Nectar research cloud designed for single-node jobs with a slower interconnect. This meant that more financial resources were available for capacity.
Was Spartan's original design "HPC in the cloud"?	No! HPC in the cloud refers to a remote third-party service that runs a HPC. Spartan was an HPC-Cloud hybrid system that combined a traditional HPC architecture and use of cloud VMs as compute nodes optimised for single-node jobs. Now it is has a "true" or "classical" HPC architecture.
Why did Spartan return to a classic HPC architecture?	 Spartan has returned to a traditional architecture because of additional funding and the desire for a consistent network to reduce issues with the parallel file system.
What are the main partitions on Spartan?	The main CPU partition is "sapphire" named after the Intel CPU, and the main GPU partition is "gpu-a100", named after the NVidia A100 TensorCore. Sapphire is the default partition for the cluster.
What is the network latency and cable type used by Spartan between compute nodes?	Spartan uses high-speed 50Gb Ethernet networking with 1.5 µsec latency.
What does Spartan use for storage?	Spartan uses IBM Spectrum Scale (previously known as GPFS), a parallel file system. The /data/gpfs storage space runs on 10K SAS disks whereas the /data/scratch	directory uses Flash storage. Home directories are on the University's NetApp NFS platform.
Which directories should jobs be launched from?	Batch jobs can be launched from a user's home directory, their project directory, or a project's scratch directory. However, the home directory is notably slower for tasks that have a large amount of I/O.
Can one access Spartan without an account?	No. To access Spartan one needs to have an account and belong to a project.
Do you need to be from the University of Melbourne to have an account on Spartan?	No. Project leaders must be a researcher at the University of Melbourne, but account holders and project members can be from anywhere.
When setting up a project on Spartan, what sort of information should be provided?	Two-three lines of explanation of what the project will be used for, any specialist software that is required, or access to specialist partitions.
   
